global:
  # -- Name of the label identifying where the time series data points come from.
  clusterLabel: cluster
  # -- Value of clusterName usually identical to cluster used in some subcharts (e.g. otel)
  clusterName: mothership
  # -- Name of the storage class used by Grafana,
  # `vmstorage` (long-term storage of raw time series data),
  # and `vmselect` (cache of query results).
  # Keep it unset or empty to leverage the advantages of
  # [default storage class](https://kubernetes.io/docs/concepts/storage/storage-classes/#default-storageclass).
  storageClass: ""

  # -- Length of the auto-generated usernames for Grafana and VictoriaMetrics.
  random_username_length: 8

  # -- Length of the auto-generated passwords for Grafana and VictoriaMetrics.
  random_password_length: 12

  # -- Custom image registry, `sveltos-dashboard` requires not empty value.
  registry: docker.io

grafana-operator:
  image:
    # -- Custom `grafana-operator` image repository.
    repository: ghcr.io/grafana/grafana-operator

cert-manager:
  # -- Whether cert-manager is present in the cluster
  enabled: true
  cluster-issuer:
    # -- Whether to create a default clusterissuer
    create: false
    # -- Default clusterissuer provider
    provider: letsencrypt
  # -- If we use letsencrypt (or similar) which email to use
  email: mail@example.net

# -- Config of `ServiceTemplate` to use `cert-manager` in `MultiClusterService`.
cert-manager-service-template:
  repo:
    name: cert-manager
    url: https://charts.jetstack.io
  chart: cert-manager:v1.16.4
  namespace: kcm-system

# -- Config of `ServiceTemplate` to use `ingress-nginx` in `MultiClusterService`.
ingress-nginx-service-template:
  repo:
    name: ingress-nginx
    url: https://kubernetes.github.io/ingress-nginx
  chart: ingress-nginx:4.12.1
  namespace: kcm-system

kcm:
  # -- K8s namespace created on installation of k0rdent/kcm.
  namespace: kcm-system

  # -- Installs `ServiceTemplates` to use charts like `kof-storage` in `MultiClusterService`.
  installTemplates: false

  serviceMonitor:
    # -- Enables the "KCM Controller Manager" Grafana dashboard.
    enabled: true

  kof:
    # -- Repo of `kof-*` helm charts.
    repo:
      name: kof
      spec:
        type: oci
        url: oci://ghcr.io/k0rdent/kof/charts

    # -- Names of secrets auto-distributed to clusters with matching labels.
    clusterProfiles:
      kof-storage-secrets:
        matchLabels:
          k0rdent.mirantis.com/kof-storage-secrets: "true"
        create_secrets: true
        secrets:
          - storage-vmuser-credentials

    operator:
      # -- Enables the `kof-operator`.
      enabled: true

      # -- Number of the `kof-operator` deployment replicas.
      replicaCount: 1

      # -- Allows regional cluster to be in another namespace than the child cluster.
      crossNamespace: false

      rbac:
        # -- Creates the `kof-mothership-kof-operator` cluster role
        # and binds it to the service account of operator.
        create: true

      # -- Image of the kof operator.
      image:
        registry: ghcr.io/k0rdent
        repository: kof/kof-operator-controller
        pullPolicy: IfNotPresent

      resources:
        # -- Minimum resources required for operator.
        requests:
          cpu: 100m
          memory: 128Mi

        # -- Maximum resources available for operator.
        limits:
          cpu: 100m
          memory: 128Mi

      autoinstrumentation:
        # -- Enable autoinstrumentation to collect metrics and traces from the operator.
        enabled: true

      serviceAccount:
        # -- Creates a service account for operator.
        create: true

        # -- Annotations for the service account of operator.
        annotations: {}

        # -- Name for the service account of operator.
        # If not set, it is generated as `kof-mothership-kof-operator`.
        name:

      ui:
        # -- Port for the web UI server.
        port: 9090

        # -- Port for Prometheus metrics receiver.
        receiverPort: 9090

victoriametrics:
  # -- Enables VictoriaMetrics.
  enabled: true

  vmcluster:
    # -- Enables high-available and fault-tolerant version of VictoriaMetrics database.
    enabled: true

    # -- The number of replicas for each metric.
    replicationFactor: 1

    # -- The number of replicas for components of cluster.
    replicaCount: 1

    # -- Days to retain the data.
    retentionPeriod: "1"

    vmselect:
      storage:
        # -- Query results cache size.
        size: 2Gi

    vmstorage:
      storage:
        # -- Long-term storage size of raw time series data.
        size: 10Gi

    vminsert:
      labels:
        # -- Label to enable mtls
        k0rdent.mirantis.com/istio-mtls-enabled: "true"

  vmalert:
    # -- Enables VMAlertManager only, as VMAlert is replaced with promxy in kof-mothership.
    enabled: true

    vmalertmanager:
      # -- `configRawYaml` of [VMAlertmanagerSpec](https://docs.victoriametrics.com/operator/api/#vmalertmanagerspec).
      # Check examples [here](https://docs.k0rdent.io/next/admin/kof/kof-alerts/#alertmanager-demo).
      config: ""

grafana:
  # -- Enables Grafana.
  enabled: true

  ingress:
    # -- Enables an ingress to access Grafana without port-forwarding.
    enabled: false

    # -- Domain name Grafana will be available at.
    host: grafana.example.net

  # -- Old option to add `GrafanaDatasource`-s.
  logSources: []

  security:
    # -- Name of secret for Grafana username/password.
    credentials_secret_name: grafana-admin-credentials

    # -- Enables auto-creation of Grafana username/password.
    create_secret: true

  pvc:
    resources:
      requests:
        # -- Size of storage for Grafana.
        storage: 200Mi

  # -- Version of Grafana to use.
  version: "10.4.18-security-01"

  dashboard:
    datasource:
      # -- Regex pattern to filter datasources.
      regex: "/promxy/"

      # -- Values of current datasource
      current:
        text: promxy
        value: promxy

    # -- Values of filters to apply.
    filters:
      cluster: mothership

    # -- Enables istio dashboards
    istio_dashboard_enabled: true

dex:
  # -- Enables Dex.
  enabled: false

  image:
    # -- Version of Dex to use.
    tag: v2.42.1

  # -- Enables the HTTPS endpoint.
  https:
    enabled: true

  config:
    # -- The identifier (issuer) URL for Dex.
    issuer: https://dex.example.com:32000

    storage:
      # -- Specifies the storage type used by Dex.
      type: memory

    web:
      # -- Address and port for the HTTPS endpoint.
      https: 0.0.0.0:5554

      # -- Path to the TLS certificate file.
      tlsCert: /etc/dex/tls/tls.crt

      # -- Path to the TLS private key file.
      tlsKey: /etc/dex/tls/tls.key

    staticClients:
      - id: grafana-id
        redirectURIs:
          - "http://localhost:3000/login/generic_oauth"
        name: "Grafana"
        secret: grafana-secret

    connectors:
      - type: google
        id: google
        name: Google
        config:
          clientID: ""
          clientSecret: ""
          redirectURI: https://dex.example.com:32000/callback

  volumes:
    - name: tls
      secret:
        secretName: dex-tls

  volumeMounts:
    - name: tls
      mountPath: /etc/dex/tls
      readOnly: true

  service:
    type: NodePort

    ports:
      http:
        port: 5556
      https:
        port: 5554
        nodePort: 32000

# -- [Docs](https://github.com/VictoriaMetrics/helm-charts/tree/master/charts/victoria-metrics-operator#parameters)
victoria-metrics-operator:
  enabled: true
  serviceMonitor:
    enabled: true
    vm: false
  operator:
    disable_prometheus_converter: true
  crds:
    plain: true
    cleanup:
      enabled: true

# -- [Docs](https://github.com/Jont828/cluster-api-visualizer/tree/main/helm#configurable-values)
cluster-api-visualizer:
  enabled: true
  image:
    # -- Custom `cluster-api-visualizer` image repository.
    repository: ghcr.io/k0rdent

# -- [Docs](https://projectsveltos.github.io/dashboard-helm-chart/#values)
sveltos-dashboard:
  enabled: true

sveltos:
  # -- Creates `ServiceMonitor`-s for Sveltos `sc-manager` and `addon-controller`.
  serviceMonitors: true

  # -- Adds Sveltos dashboard to Grafana.
  grafanaDashboard: true

promxy:
  # -- Enables `kof-mothership-promxy` deployment.
  enabled: true

  # -- Number of replicated promxy pods.
  replicaCount: 1

  # -- Promxy image to use.
  image:
    registry: quay.io
    repository: jacksontj/promxy
    tag: v0.0.93
    pullPolicy: IfNotPresent

  serviceAccount:
    # -- Creates a service account for promxy.
    create: true

    # -- Annotations for the service account of promxy.
    annotations: {}

    # -- Name for the service account of promxy.
    # If not set, it is generated as `kof-mothership-promxy`.
    name:

  # -- Config of `kof-mothership-promxy`
  # [Service](https://kubernetes.io/docs/concepts/services-networking/service/).
  service:
    enabled: true
    type: ClusterIP
    servicePort: 8082
    annotations: {}
    extraLabels: {}
    clusterIP: ""
    externalIPs: []
    loadBalancerIP: ""
    loadBalancerSourceRanges: []

  # -- Config of `kof-mothership-promxy`
  # [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/).
  ingress:
    enabled: false
    ingressClassName: nginx
    annotations: {}
    extraLabels: {}
    path: /
    pathType: Prefix
    hosts:
      - example.com
    tls: []

  resources:
    # -- Minimum resources required for the `promxy` container
    # in the pods of `kof-mothership-promxy` deployment.
    requests:
      cpu: 100m
      memory: 128Mi

    # -- Maximum resources available for the `promxy` container
    # in the pods of `kof-mothership-promxy` deployment.
    limits:
      cpu: 100m
      memory: 128Mi

  # -- Extra command line arguments passed as `--key=value` to the `/bin/promxy`.
  extraArgs:
    log-level: "info"
    "web.external-url": http://127.0.0.1:8082

  configmapReload:
    resources:
      # -- Minimum resources required for the `promxy-server-configmap-reload` container
      # in the pods of `kof-mothership-promxy` deployment.
      requests:
        cpu: 0.02
        memory: 20Mi

      # -- Maximum resources available for the `promxy-server-configmap-reload` container
      # in the pods of `kof-mothership-promxy` deployment.
      limits:
        cpu: 0.02
        memory: 20Mi

# See ./templates/prometheus/_README.md
# @ignored
kube-state-metrics:
  enabled: true
# @ignored
kubeApiServer:
  enabled: true
# @ignored
kubeControllerManager:
  enabled: true
# @ignored
kubeEtcd:
  enabled: true
# @ignored
kubelet:
  enabled: true
# @ignored
kubeProxy:
  enabled: true
# @ignored
kubeScheduler:
  enabled: true
# @ignored
prometheusOperator:
  kubeletService: {}
# @ignored
windowsMonitoring: {}

## custom Rules to override "for" and "severity" in defaultRules
##
# @ignored
customRules:
  {}
  # AlertmanagerFailedReload:
  #   for: 3m
  # AlertmanagerMembersInconsistent:
  #   for: 5m
  #   severity: "warning"

## Create default rules for monitoring the cluster
##
# @ignored
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    configReloaders: true
    general: true
    k8sContainerCpuUsageSecondsTotal: true
    k8sContainerMemoryCache: true
    k8sContainerMemoryRss: true
    k8sContainerMemorySwap: true
    k8sContainerResource: true
    k8sContainerMemoryWorkingSetBytes: true
    k8sPodOwner: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubeControllerManager: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeSchedulerAlerting: true
    kubeSchedulerRecording: true
    kubeStateMetrics: true
    mothershipControlPlane: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
    windows: true

  ## Reduce app namespace alert scope
  appNamespacesTarget: ".*"

  ## Set keep_firing_for for all alerts
  keepFiringFor: ""

  ## Labels for default rules
  labels: {}
  ## Annotations for default rules
  annotations: {}

  ## Additional labels for PrometheusRule alerts
  additionalRuleLabels: {}

  ## Additional annotations for PrometheusRule alerts
  additionalRuleAnnotations: {}

  ## Additional labels for specific PrometheusRule alert groups
  additionalRuleGroupLabels:
    alertmanager: {}
    etcd: {}
    configReloaders: {}
    general: {}
    k8sContainerCpuUsageSecondsTotal: {}
    k8sContainerMemoryCache: {}
    k8sContainerMemoryRss: {}
    k8sContainerMemorySwap: {}
    k8sContainerResource: {}
    k8sPodOwner: {}
    kubeApiserverAvailability: {}
    kubeApiserverBurnrate: {}
    kubeApiserverHistogram: {}
    kubeApiserverSlos: {}
    kubeControllerManager: {}
    kubelet: {}
    kubeProxy: {}
    kubePrometheusGeneral: {}
    kubePrometheusNodeRecording: {}
    kubernetesApps: {}
    kubernetesResources: {}
    kubernetesStorage: {}
    kubernetesSystem: {}
    kubeSchedulerAlerting: {}
    kubeSchedulerRecording: {}
    kubeStateMetrics: {}
    mothershipControlPlane: {}
    network: {}
    node: {}
    nodeExporterAlerting: {}
    nodeExporterRecording: {}
    prometheus: {}
    prometheusOperator: {}

  ## Additional annotations for specific PrometheusRule alerts groups
  additionalRuleGroupAnnotations:
    alertmanager: {}
    etcd: {}
    configReloaders: {}
    general: {}
    k8sContainerCpuUsageSecondsTotal: {}
    k8sContainerMemoryCache: {}
    k8sContainerMemoryRss: {}
    k8sContainerMemorySwap: {}
    k8sContainerResource: {}
    k8sPodOwner: {}
    kubeApiserverAvailability: {}
    kubeApiserverBurnrate: {}
    kubeApiserverHistogram: {}
    kubeApiserverSlos: {}
    kubeControllerManager: {}
    kubelet: {}
    kubeProxy: {}
    kubePrometheusGeneral: {}
    kubePrometheusNodeRecording: {}
    kubernetesApps: {}
    kubernetesResources: {}
    kubernetesStorage: {}
    kubernetesSystem: {}
    kubeSchedulerAlerting: {}
    kubeSchedulerRecording: {}
    kubeStateMetrics: {}
    mothershipControlPlane: {}
    network: {}
    node: {}
    nodeExporterAlerting: {}
    nodeExporterRecording: {}
    prometheus: {}
    prometheusOperator: {}

  additionalAggregationLabels: []

  ## Prefix for runbook URLs. Use this to override the first part of the runbookURLs that is common to all rules.
  runbookUrl: "https://runbooks.prometheus-operator.dev/runbooks"

  node:
    fsSelector: 'fstype!=""'
    # fsSelector: 'fstype=~"ext[234]|btrfs|xfs|zfs"'

  ## Disabled PrometheusRule alerts
  disabled: {}
  # KubeAPIDown: true
  # NodeRAIDDegraded: true

## Create default rules for monitoring the cluster
##
# @ignored
mothershipRules:
  create: true
  rules:
    controlPlane: true
    serviceApiAvailability: true

  ## Reduce app namespace alert scope
  appNamespacesTarget: ".*"

  ## Set keep_firing_for for all alerts
  keepFiringFor: ""

  ## Labels for default rules
  labels: {}
  ## Annotations for default rules
  annotations: {}

  ## Additional labels for PrometheusRule alerts
  additionalRuleLabels: {}

  ## Additional annotations for PrometheusRule alerts
  additionalRuleAnnotations: {}

  ## Additional labels for specific PrometheusRule alert groups
  additionalRuleGroupLabels:
    controlPlane: {}
    serviceApiAvailability: {}

  ## Additional annotations for specific PrometheusRule alerts groups
  additionalRuleGroupAnnotations:
    controlPlane: {}
    serviceApiAvailability: {}

  additionalAggregationLabels: []

  ## Prefix for runbook URLs. Use this to override the first part of the runbookURLs that is common to all rules.
  runbookUrl: "https://docs.k0rdent.io/next/admin/kof/"

# -- Cluster-specific patch of Prometheus alerting rules,
# e.g. `cluster1.alertgroup1.alert1.expr` overriding the threshold `> ( 25 / 100 )`
# and adding `{cluster="cluster1"}` filter, or just adding whole new rules
clusterAlertRules:
  {}
  # cluster1:
  #   kubernetes-resources:
  #     CPUThrottlingHigh:
  #       expr: |-
  #         sum(increase(container_cpu_cfs_throttled_periods_total{cluster="cluster1", container!="", job="kubelet", metrics_path="/metrics/cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)
  #           / on (cluster, namespace, pod, container, instance) group_left
  #         sum(increase(container_cpu_cfs_periods_total{cluster="cluster1", job="kubelet", metrics_path="/metrics/cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)
  #           > ( 42 / 100 )

# -- Patch of default Prometheus alerting rules,
# e.g. `alertgroup1.alert1` overriding `for` field and adding
# `{cluster!~"^cluster1$|^cluster10$"}` for rules overridden in `clusterRulesPatch`,
# or just adding whole new rules
defaultAlertRules:
  # kubernetes-resources:
  #   CPUThrottlingHigh:
  #     for: 10m
  #     expr: |-
  #       sum(increase(container_cpu_cfs_throttled_periods_total{cluster!~"^cluster1$|^cluster10$", container!="", job="kubelet", metrics_path="/metrics/cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)
  #         / on (cluster, namespace, pod, container, instance) group_left
  #       sum(increase(container_cpu_cfs_periods_total{cluster!~"^cluster1$|^cluster10$", job="kubelet", metrics_path="/metrics/cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)
  #         > ( 25 / 100 )
  #
  # New rule based on https://github.com/samber/awesome-prometheus-alerts/blob/2025-04-17.1/dist/rules/docker-containers/google-cadvisor.yml#L34
  # adapted for multi-cluster case:
  docker-containers:
    ContainerHighMemoryUsage:
      expr: |-
        sum(container_memory_working_set_bytes{pod!=""}) by (cluster, namespace, pod)
        / sum(container_spec_memory_limit_bytes > 0) by (cluster, namespace, pod) * 100
        > 80
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: Container High Memory usage ({{ $labels.cluster }}/{{ $labels.namespace }}/{{ $labels.pod }})
        description: "Container Memory usage is above 80%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

# -- Cluster-specific patch of Prometheus recording rules,
# e.g. `regionalCluster1.recordGroup1` overriding whole group of rules
# (because `record` is not unique), or adding new groups
clusterRecordRules:
  {}
  # regional1:
  #   kube-prometheus-general.rules:
  #     - expr: count without(instance, pod, node) (up == 1)
  #       record: count:up1
  #     - expr: count without(instance, pod, node) (up == 0)
  #       record: count:up0
  #     - expr: count without(instance, pod, node) (up{cluster="child2"} >= 0)
  #       record: count:child2_up_or_down

# -- Patch of default Prometheus recording rules,
# e.g. `recordgroup1` overriding whole group of rules (`record` is not unique),
# or adding new groups
defaultRecordRules:
  {}
  # kube-prometheus-general.rules:
  #   - expr: count without(instance, pod, node) (up == 1)
  #     record: count:up1
  #   - expr: count without(instance, pod, node) (up == 0)
  #     record: count:up0
  #   - expr: count without(instance, pod, node) (up <= 1)
  #     record: count:up_or_down
  # kube-prometheus-general-default-test.rules:
  #   - expr: count without(instance, pod, node) (up >= 0)
  #     record: count:up_or_down
